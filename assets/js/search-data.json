{
  
    
        "post0": {
            "title": "European Language Resource Coordination (ELRC)",
            "content": "Available for Download &#9989; . ⚠️ Always check the license of the data source before using the data ⚠️ . Main page: https://elrc-share.eu/ | Data Browse Link: https://elrc-share.eu/repository/search/ | Format: .tmx | . Brief Description . The ELRC-SHARE repository is used for documenting, storing, browsing and accessing Language Resources that are collected through the European Language Resource Coordination and considered useful for feeding the CEF Automated Translation (CEF.AT) platform. . Other Notes . NA . Code to Extract to a Pandas DataFrame . from pathlib import Path import pandas as pd from tmx2dataframe import tmx2dataframe metadata, df = tmx2dataframe.read(&#39;elrc/citizens_information_en-ga.tmx&#39;) print(len(df)) df.head() . 10297 . source_language source_sentence target_language target_sentence . 0 en | about Citizens Information | ga | maidir le faisnéis do shaoránaigh | . 1 en | the Citizens Information Board is the statutor... | ga | is é an Bord um fhaisnéis do shaoránaigh ( BFS... | . 2 en | it provides the Citizens Information website ,... | ga | cuireann sé an láithreán gréasáin um fhaisnéis... | . 3 en | it also funds and supports the Money Advice an... | ga | cuireann sé maoiniú agus tacaíocht ar fáil fre... | . 4 en | Citizensinformation.ie provides comprehensive ... | ga | cuireann citizensinformation.ie faisnéis chuim... | . Code to Interate and Extract all .tmx files downloaded . from fastprogress.fastprogress import master_bar, progress_bar import gc lang=&#39;ga&#39; dir_path = Path(f&#39;elrc&#39;) samp_count=0 for f in progress_bar(list(dir_path.iterdir())): if f.suffix == &#39;.tmx&#39;: try: _, df = tmx2dataframe.read(str(f)) # If target_language in dataframe contains the language string (like &#39;ga&#39;) df.target_language = df.target_language.str.lower() if len(df[df.target_language.str.contains(lang)]) &gt; 0: ga_df = df[df.target_language.str.contains(lang)].copy() ga_df[&#39;filepath&#39;] = str(f) except:pass #print(f&quot;Couldn&#39;t open {f}&quot;) var_exists = &#39;ga_df&#39; in locals() or &#39;ga_df&#39; in globals() if var_exists: #print(f&#39;{len(ga_df)} samples found in {f}&#39;) samp_count+=len(ga_df) ga_df.reset_index(inplace=True, drop=True) ga_df.to_csv(f&#39;{str(f).lower()}.csv&#39;) del ga_df gc.collect() #else: print(f&#39;No {lang} text found in {f} ?&#39;) #print() print(f&#39;{samp_count} total text samples extracted&#39;) . &lt;progress value=&#39;77&#39; class=&#39;&#39; max=&#39;77&#39;, style=&#39;width:300px; height:20px; vertical-align: middle;&#39;&gt;&lt;/progress&gt; 100.00% [77/77 00:14&lt;00:00] 34235 total text samples extracted . Compile Saved CSVs . from fastprogress.fastprogress import master_bar, progress_bar import gc lang=&#39;ga&#39; dir_path = Path(f&#39;elrc&#39;) f_list = [] for f in list(dir_path.iterdir()): if f.suffix == &#39;.csv&#39;: f_list.append(f) for i,f in enumerate(progress_bar(f_list)): try: if i == 0: ga_df = pd.read_csv(f, index_col=0) tmp = pd.read_csv(f, index_col=0) ga_df = pd.concat([ga_df, tmp]) except: print(f&#39;Error with opening {f}&#39;) ga_df.reset_index(inplace=True, drop=True) print(len(ga_df)) ga_df.to_csv(&#39;elrc_en-ga_compiled_2020-06-11.csv&#39;, index=False) ga_df.head() . &lt;progress value=&#39;34&#39; class=&#39;&#39; max=&#39;34&#39;, style=&#39;width:300px; height:20px; vertical-align: middle;&#39;&gt;&lt;/progress&gt; 100.00% [34/34 00:00&lt;00:00] 34243 . source_language source_sentence target_language target_sentence filepath . 0 en | Press release31 March 2020Brussels | ga | Preaseisiúint March 31, 2020An Bhruiséil | elrc/covid19_eu_presscorner_en-ga.tmx | . 1 en | State aid: Coronavirus: Irish Repayable Advanc... | ga | Státchabhair: An coróinvíreas: Scéim Réamhíoca... | elrc/covid19_eu_presscorner_en-ga.tmx | . 2 en | (i) Direct grants, selective tax advantages an... | ga | (i) an deontas díreach, buntáistí cánach roghn... | elrc/covid19_eu_presscorner_en-ga.tmx | . 3 en | (i) Direct grants, equity injections, selectiv... | ga | (i) Deontais dhíreacha, instealltaí cothromais... | elrc/covid19_eu_presscorner_en-ga.tmx | . 4 en | State aid_coronavirus_IrelandThe European Comm... | ga | Bearta tacaíochta na hÉireann | elrc/covid19_eu_presscorner_en-ga.tmx | .",
            "url": "https://nlp-irish.github.io/nlp.irish/elrc,/translation/2020/06/11/ELRC_European_Language_Resource_Coordination.html",
            "relUrl": "/elrc,/translation/2020/06/11/ELRC_European_Language_Resource_Coordination.html",
            "date": " • Jun 11, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "DGT-Translation Memory (DGT-TM)",
            "content": "Available for Download &#9989; . ⚠️ Always check the license of the data source before using the data ⚠️ . Link: https://ec.europa.eu/jrc/en/language-technologies/dgt-translation-memory | Format: .tmx | NOTE: There are no Irish translations in: DGT-TM Version 1 (Released in 2007) | DGT-TM-release 2011 | . | &quot;DGT-TM-release 2012&quot; is the first release with Irish translations | . | . Brief Description . A parallel multilingual corpus of the European Union’s legislative documents (Acquis Communautaire) in 24 EU languages. The aligned translation units have been provided by the Directorate-General for Translation of the European Commission by extraction from one of its large shared translation memories in EURAMIS (European advanced multilingual information system). This memory contains most, although not all, of the documents which make up the Acquis Communautaire, as well as some other documents which are not part of the Acquis. . Other Notes . See the section on the EU site called &quot;How to produce bilingual extractions&quot; for a java-based alternative to extracting the TMX files . Code to Extract TMX to DataFrame . Pip install the tmx2dataframe package here . pip install tmx2dataframe . Extract from a single TMX file . from pathlib import Path import pandas as pd from tmx2dataframe import tmx2dataframe metadata, df = tmx2dataframe.read(&#39;Volume_1/22003D0033.tmx&#39;) df.head() . source_language source_sentence target_language target_sentence . 0 EN-GB | Decision of the EEA Joint Committee No 33/2003... | ET-01 | EMP Ühiskomitee otsus nr 33/2003, 14. märts 20... | . 1 EN-GB | THE EEA JOINT COMMITTEE, | ET-01 | EMP ÜHISKOMITEE, | . 2 EN-GB | Having regard to the Agreement on the European... | ET-01 | võttes arvesse Euroopa Majanduspiirkonna lepin... | . 3 EN-GB | HAS DECIDED AS FOLLOWS: | ET-01 | ON VASTU VÕTNUD JÄRGMISE OTSUSE: | . 4 EN-GB | Article 1 | ET-01 | Artikkel 1 | . df.source_sentence[0], df.target_sentence[0] . (&#39;Decision of the EEA Joint Committee No 33/2003 of 14 March 2003 amending Annex XIII (Transport) to the EEA Agreement&#39;, &#39;EMP Ühiskomitee otsus nr 33/2003, 14. märts 2003, millega muudetakse EMP lepingu XIII lisa (transport)&#39;) . len(df), len(df.target_sentence[1].split()) . (35, 2) . The metadata is also included: . metadata . {&#39;creationtool&#39;: &#39;tmexport2 2.32 27-03-2007&#39;, &#39;adminlang&#39;: &#39;EN-US&#39;, &#39;srclang&#39;: &#39;EN-GB&#39;} . Extract language-specific sentences from multiple volumes and TMX files: . from pathlib import Path import gc import pandas as pd from tmx2dataframe import tmx2dataframe from fastprogress.fastprogress import master_bar, progress_bar lang=&#39;GA&#39; #yr=&#39;2013&#39; yr_list=[] for y in range(2,10): yr_list.append(f&#39;201{y}&#39;) # For each release year for yr in yr_list: dir_path = Path(f&#39;{yr}_release&#39;) dir_list=[] for dd in dir_path.iterdir(): if dd.is_dir(): dir_list.append(dd) mb = master_bar(dir_list) # For directory in a specific release year for d in mb: if d.is_dir() &amp; (d.suffix != &#39;.zip&#39;): # For each file in a specific directory for f in progress_bar(list(d.iterdir()), parent=mb): if f.suffix == &#39;.tmx&#39;: try: _, df = tmx2dataframe.read(str(f)) # If target_language in dataframe contains the language string (like &#39;GA&#39;) if len(df[df.target_language.str.contains(lang)]) &gt; 0: tmp = df[df.target_language.str.contains(lang)].copy() tmp[&#39;filepath&#39;] = str(f) var_exists = &#39;ga_df&#39; in locals() or &#39;ga_df&#39; in globals() if var_exists: ga_df = pd.concat([ga_df, tmp]) else: ga_df = tmp except: print(f&quot;Couldn&#39;t open {f} in {d}&quot;) print(f&#39;{yr} DONE!&#39;) var_exists = &#39;ga_df&#39; in locals() or &#39;ga_df&#39; in globals() if var_exists: print(f&#39;{len(ga_df)} samples found in {yr} release&#39;) ga_df.reset_index(inplace=True, drop=True) ga_df.to_csv(f&#39;dgt_tm_{yr}_release_en-ga.csv&#39;) del ga_df gc.collect() else: print(f&#39;No {lang} text found in {yr} release&#39;) print() #ga_df.head() . 2012 DONE! 2848 samples found in 2012 release . 2013 DONE! No GA text found in 2013 release . 2014 DONE! 41461 samples found in 2014 release . 2015 DONE! 7673 samples found in 2015 release . 2016 DONE! 9127 samples found in 2016 release . 2017 DONE! 37181 samples found in 2017 release . 2018 DONE! 30014 samples found in 2018 release . 2019 DONE! 53652 samples found in 2019 release . Compile all release years . for y in range(2,10): try: if y == 2: ga_df = pd.read_csv(f&#39;dgt_tm_201{y}_release_en-ga.csv&#39;, index_col=0) tmp = pd.read_csv(f&#39;dgt_tm_201{y}_release_en-ga.csv&#39;, index_col=0) ga_df = pd.concat([ga_df, tmp]) except: print(f&#39;Error with opening dgt_tm_201{y}_release_en-ga.csv&#39;) ga_df.reset_index(inplace=True, drop=True) print(len(ga_df)) ga_df.to_csv(&#39;dgt_tm_2012-2019_releases_en-ga.csv&#39;, index=False) ga_df.head() . 190500 . source_language source_sentence target_language target_sentence filepath . 0 EN-GB | Regulation (EU) No 1174/2011 of the European P... | GA-IE | Rialachán (AE) Uimh. 1174/2011 ó Pharlaimint n... | 2012_release/Vol_2011_4/32011R1174.tmx | . 1 EN-GB | of 16 November 2011 | GA-IE | an 16 Samhain 2011 | 2012_release/Vol_2011_4/32011R1174.tmx | . 2 EN-GB | on enforcement measures to correct excessive m... | GA-IE | maidir le bearta forfheidhmiúcháin chun míchot... | 2012_release/Vol_2011_4/32011R1174.tmx | . 3 EN-GB | THE EUROPEAN PARLIAMENT AND THE COUNCIL OF THE... | GA-IE | TÁ PARLAIMINT NA hEORPA AGUS COMHAIRLE AN AONT... | 2012_release/Vol_2011_4/32011R1174.tmx | . 4 EN-GB | Having regard to the Treaty on the Functioning... | GA-IE | Ag féachaint don Chonradh ar Fheidhmiú an Aont... | 2012_release/Vol_2011_4/32011R1174.tmx | . Other Files . file_list.txt . The .zip files also contain a .txt file with the original filename and what languages it is available in: . df_ls = pd.read_csv(&#39;Volume_1/file_list.txt&#39;, header=None) df_ls.columns = [&#39;fst&#39;] df_ls.head() . fst . 0 21970A0720(01).tmx EN:54 BG:34 CS:35 ET:44 FR... | . 1 21970A1123(01).tmx EN:631 BG:569 ET:547 FR:55... | . 2 21972A0722(03).tmx EN:4674 BG:1436 HU:1629 LT... | . 3 21972A0722(04).tmx EN:29 BG:16 FR:9 HU:28 MT:... | . 4 21972A0722(05).tmx EN:251 BG:214 FR:219 | . df_ls.fst[0] . &#39;21970A0720(01).tmx EN:54 BG:34 CS:35 ET:44 FR:41 HU:39 LV:41 MT:42 PL:40 SK:35 SL:41 &#39; .",
            "url": "https://nlp-irish.github.io/nlp.irish/dgt-tm,/dgt-tm3/2020/06/11/DGT-Translation-Memories-DGT-TM.html",
            "relUrl": "/dgt-tm,/dgt-tm3/2020/06/11/DGT-Translation-Memories-DGT-TM.html",
            "date": " • Jun 11, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Digital Corpus of the European Parliament (DCEP)",
            "content": "Available for Download &#9989; . ⚠️ Always check the license of the data source before using the data ⚠️ . Main page: https://ec.europa.eu/jrc/en/language-technologies/dcep | Download Link: https://wt-public.emm4u.eu/Resources/DCEP-2013/DCEP-Download-Page.html | Extraction Instructions: https://wt-public.emm4u.eu/Resources/DCEP-2013/DCEP-extract-README.html | Format: Sentence-aligned data is in plain text | . Brief Description . Contains the majority of the documents published on the European Parliament&#39;s official website. It comprises a variety of document types, from press releases to session and legislative documents related to European Parliament&#39;s activities and bodies. The current version of the corpus contains documents that were produced between 2001 and 2012. . Other Notes . NA . Code to Extract Files to Pandas DataFrame . GA-EN specific instructions are below, for more info see the offical extraction instructions page . Download and extract language files | !wget -q http://optima.jrc.it/Resources/DCEP-2013/sentences/DCEP-sentence-GA-pub.tar.bz2 . !wget -q http://optima.jrc.it/Resources/DCEP-2013/sentences/DCEP-sentence-EN-pub.tar.bz2 . !tar jxf DCEP-sentence-GA-pub.tar.bz2 . !tar jxf DCEP-sentence-EN-pub.tar.bz2 . Download and extract language pair info | !wget -q http://optima.jrc.it/Resources/DCEP-2013/langpairs/DCEP-EN-GA.tar.bz2 . !tar jxf DCEP-EN-GA.tar.bz2 . Download and extract alignment scripts | !wget -q http://optima.jrc.it/Resources/DCEP-2013/DCEP-extract-scripts.tar.bz2 . !tar jxvf DCEP-extract-scripts.tar.bz2 . Create aligned file | The --numbering-filter is a crude but useful heuristic that attempts to drop numberings and short titles from the output. It works simply by matching sentences on both sides against a Unicode regex that looks for two alphabetic characters with space between them. . The --length-filter-level=LENGTH_FILTER_LEVEL argument is used to throw away as suspicious all bisentences where the ratio of the shorter and the longer sentence (in character length) is less than LENGTH_FILTER_LEVEL percent. . !cd dcep &amp;&amp; ./src/languagepair.py --numbering-filter --length-filter-level=40 EN-GA &gt; EN-GA-bisentences.txt . Open as a Dataframe | import pandas as pd df = pd.read_csv(&#39;dcep/EN-GA-bisentences.txt&#39;, header=None, sep=&#39; t&#39;) df.columns = [&#39;en&#39;, &#39;ga&#39;] df.to_csv(&#39;dcep_en-ga_bisentences.csv&#39;) print(len(df)) df.head() . 46147 . en ga . 0 RULES OF PROCEDURE | RIALACHA NÓS IMEACHTA | . 1 7th parliamentary term | 7ú téarma parlaiminteach | . 2 July 2009 | Iúil 2009 | . 3 Interpretations of the Rules (pursuant to Rule... | Tá léirmhínithe ar na Rialacha (de bhun Riail ... | . 4 MEMBERS, PARLIAMENT BODIES AND POLITICAL GROUPS | FEISIRÍ, COMHLACHTAÍ PARLAIMINTE AGUS GRÚPAÍ P... | .",
            "url": "https://nlp-irish.github.io/nlp.irish/dcep,/translation/2020/06/11/DCEP-Digital-Corpus-of-the-European-Parliament.html",
            "relUrl": "/dcep,/translation/2020/06/11/DCEP-Digital-Corpus-of-the-European-Parliament.html",
            "date": " • Jun 11, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About",
          "content": "Unlike English, there didn’t seem to be a easily discoverable collection of definitive, open source Irish language datasets for NLP research. nlp.Irish hopes to address that by cataloguing the open source datasets available online today. . Like to contribute? . All of the information on this site is open source and is hosted at https://github.com/nlp-irish/nlp.irish To contribute: . Open a pull request and edit the index.html file to include the link and other information about the dataset | Submit the pull request and we’ll review it before merging | Done! | Not familiar with Github? No worries, reach out to @mcgenergy on Twitter if you’d like to contribute and add links to new datasets or any other useful information . .",
          "url": "https://nlp-irish.github.io/nlp.irish/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  
      ,"page2": {
          "title": "",
          "content": ". A collection of descriptions, sources and extraction instructions for Irish language natural language processing (NLP) text datasets for NLP research. . Would you like to add to this collection? Great! This site is hosted on GitHub, head up to the About section to see how to contribute . Datasets Described Here . Parallel Corpora: . ELRC, European Language Resource Coordination | DGT-TM, DGT-Translation Memory | DCEP, Digital Corpus of the European Parliament | . Monolingua Irish Corpora: . Task-specific corpora: . ALL DATASETS 👇 .",
          "url": "https://nlp-irish.github.io/nlp.irish/",
          "relUrl": "/",
          "date": ""
      }
      
  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://nlp-irish.github.io/nlp.irish/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}